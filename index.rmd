---
title: "Nick Strayer"
output:
  html_document:
    css: styles.css
    toc: true
    toc_depth: 2
    toc_float: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)

library(tidyverse)
library(magrittr)
library(glue)
library(googlesheets4)
library(r2d3)

# Public website, public sheet
googlesheets4::sheets_deauth()
projects_data <- read_sheet("https://docs.google.com/spreadsheets/d/1i4PobTTNsYJptE9KvMCiYq4oWEZ99WADJWqXVk4zDhE/edit?usp=sharing")

image <- png::readPNG('images/website_header.png') %>% 
  extract(,,1)

width <- ncol(image)
height <- nrow(image)

image_tidy <- image %>% 
  as_tibble() %>% 
  set_colnames(1:width) %>% 
  mutate(y = 1:height) %>% 
  gather(x, value, -y) %>% 
  filter(value == 0) %>% 
  transmute(
    x = as.integer(x)/width,
    y = y/height,
    dist_from_center = (x - 0.5)^2 + (y - 0.5)^2
  ) %>% 
  arrange(dist_from_center) %>% 
  select(-dist_from_center)

num_points <- nrow(image_tidy)

num_lines <- 25
num_x_points <- ceiling(num_points/num_lines)

x <- seq(0,1,length.out = num_x_points)

get_beta <- function(shape1, shape2){
  tibble(
    x = x, 
    y = dbeta(x,shape1 = shape1, shape2 = shape2),
    class = glue::glue('{shape1},{shape2}')
  )
}
beta_data <- expand.grid(
  shape1 = 2,
  shape2 = seq(1.5, 10, length.out = num_lines)
) %$% 
  purrr::map2_df(shape1, shape2, get_beta) %>% 
  head(num_points) %>% 
  mutate(y = -y/max(y) + 1)

# ggplot(beta_data, aes(x = x, y = y, color = class)) +
#   geom_line() +
#   guides(color = FALSE)

htmltools::tagList(rmarkdown::html_dependency_font_awesome())
```



```{r headerPlot}
r2d3::r2d3(
  data = list(text = image_tidy,beta = beta_data), 
  dependencies = c('javascript/regl.min.js', "javascript/helpers.js"), 
  container = 'div', 
  width = "100%",
  script = "javascript/particles.js")
```


## About


I have been extremely lucky to work in many different realms, including as a [Journalist at the New York Times](http://www.nytimes.com/interactive/2016/08/26/us/college-student-migration.html), data scientist at the [Johns Hopkins Data Science Lab](http://jhudatascience.org/) and [Dealer.com](http://www.dealer.com/) in Vermont, and "data artist in residence" at startup [Conduce](https://www.conduce.com/) in California. 

Currently, I am a PhD candidate in biostatistics at Vanderbilt University. I received my undergraduate degree from the University of Vermont where I majored in __mathematics__ and __statistics__ and minored in __computer science.__

My research focuses on __unsupervized and semi-supervized methods__ for exploring large omics datasets, with a heavy focus on __visualization__. 

I like data. Manipulating it, modeling it, making it (simulation), visualizing it and yes, even cleaning it. I do these things with some combination of __R__, __Python__, and __Javascript__ (d3.js in particular). Most recently I have been fascinated with conveying complex statistical topics and methods using [intuitive](http://nickstrayer.me/binomialFun/confidenceIntervals) and [interactive](http://nickstrayer.me/likelihood) [graphics.](http://nickstrayer.me/binomialFun/)

If you want to read about me and my pursuits in a more eloquently written form, I was recently [profiled](https://www.uvm.edu/uvmnews/news/deeper-story-data) by my alma mater.

When I am not in "school mode" I love to bike places, read science fiction, take photos, and wander around gardens/musuems.


Have a fantastic day!


## Projects


For a much more up-to-date and topical list of my work, check out the data science/statisics/visualization blog that I run with [Lucy D'Agostino McGowan](https://www.lucymcgowan.com/): [Live Free or Dichotomize](http://livefreeordichotomize.com/). 

```{r, results = 'asis'}
projects_gathered <- projects_data %>% 
  mutate(id = 1:n()) %>% 
  mutate_all(~ifelse(. == "NA", NA, .)) %>% 
  pivot_longer(
     starts_with('description'),
     names_to = 'description_num',
     values_to = 'description',
     values_drop_na = TRUE
   ) %>% 
  group_by(id) %>% 
  mutate(description_bullets = paste0("<li>", description, "</li>", collapse = "\n") ) %>% 
  ungroup() %>% 
  filter(description_num == 'description_1') 

github_icon <- "<i class='fa fa-github fa-lg' style='padding-right:5px' aria-hidden='true'></i>"
link_icon <- "<i class='fa fa-home fa-lg' style='padding-left:5px' aria-hidden='true'></i>"

projects_gathered %>% 
  mutate(
    github_link = ifelse(
      is.na(github), 
      "", 
      glue("<a href='{github}'>{github_icon}</a>")
    ),
    main_link = glue("<a href='{link}'>{link_icon}</a>"),
    all_links = glue("<p class='links'>{github_link} {main_link}</p>")
  ) %>% 
  glue_data(
    "<div class='project-entry'>",
      "<h3> <a href='{link}'>{title}</a> </h3>",
      "<div class='photo_and_description'>",
        "<img src='{photo}'>",
        "<div class='description'>",
          "<ul class='description-list'> {description_bullets} </ul>",
          "{all_links}",
        "</div>",
      "</div>",
    "</div>", 
    "<hr>"
  )
```



## CV/Resume

```{r, cache = TRUE, include = FALSE}
# Read in all data and initialize a CV printer object
cv_printer <- datadrivencv::CV_Printer$new(
  data_location = "https://docs.google.com/spreadsheets/d/14MQICF2F8-vf8CKPF1m4lyGKO6_thG-4aSwat1e2TWc",
  pdf_location = "https://github.com/nstrayer/cv/raw/master/strayer_cv.pdf",
  html_location = "nickstrayer.me/cv/")

positions <- cv_printer$position_data %>% 
  mutate(
    id = row_number(),
    title = stringr::str_remove_all(title, '(\\(.+?\\))|(\\[)|(\\])'),
    section = stringr::str_replace_all(section, "_", " ") %>% stringr::str_to_title()
  )

combination_indices <- function(n){
  rep_counts <- (n:1) - 1
  tibble(
    a = rep(1:n, times = rep_counts),
    b = purrr::flatten_int( purrr::map(rep_counts, ~{tail(1:n, .x)}) )
  )
}

edges <- positions %>% 
  select(id, start, end) %>% 
  mutate(
    end = ifelse(end == "Current", lubridate::year(lubridate::ymd(Sys.Date())), end),
    start = ifelse(start == "N/A", end, start)
  ) %>% 
  purrr::pmap_dfr(function(id, start, end){
    tibble(
      year = start:end,
      id = id
    )
  }) %>% 
  group_by(year) %>% 
  nest() %>% 
  dplyr::rename(ids_for_year = data) %>% 
  purrr::pmap_dfr(function(year, ids_for_year){
    combination_indices(nrow(ids_for_year)) %>% 
      transmute(
        year = year,
        source = ids_for_year$id[a],
        target = ids_for_year$id[b]
      )
  })
```

```{r}

r2d3::r2d3(system.file("js/cv_network.js", package = "datadrivencv"),
           data = list(
            nodes = positions %>% select(-in_resume, -end_num, -timeline),
            edges = edges
          ),
           width = "100%",
           height = "300px",
           elementId = "cv_network")
```


Want a longer list of the stuff I've done related to my career? I have a __CV__!

- [HTML version of CV with clickable links](http://nickstrayer.me/cv)
- [PDF version for printing](https://github.com/nstrayer/cv/raw/master/strayer_cv.pdf)


Need a short and to-the-point single page annotation of my data-science career? Try my __resume__!

- [HTML](http://nickstrayer.me/cv/resume.html)
- [PDF](https://github.com/nstrayer/cv/raw/master/strayer_resume.pdf)

Interested in how I made these? Check out the repo: [github.com/nstrayer/cv](https://github.com/nstrayer/cv)


## Contact

I am always interested in getting involved in new projects or just connecting with others. Feel free
to get in touch!

**email:** n.strayer (at) vanderbilt (dot) edu


**twitter:** <a href="https://twitter.com/NicholasStrayer" target="_blank">NicholasStrayer </a>
   

**github:** <a href="https://github.com/nstrayer" target="_blank">nstrayer </a>
